{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Part 1: Dataset Simulation",
   "id": "dda19df4dd0b9191"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import random\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import re"
   ],
   "id": "d6e323a4135a2aab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# CONFIGURATION\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "client = genai.Client(api_key=API_KEY)\n",
    "\n",
    "# DEFINE THE GENAI FUNCTION for TEXT GENERATION\n",
    "def generate_customer_feedback(persona, sentiment, model=\"gemini-2.0-flash\", num_sentences=200):\n",
    "    \"\"\"\n",
    "    Sends a prompt to Gemini to generate realistic text and returns a list of strings.\n",
    "    This function is defensive: it will try multiple parsing strategies and always\n",
    "    return a list of length `num_sentences` (padding/repeating if necessary).\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are simulating a customer database for a bank.\n",
    "    Generate exactly {num_sentences} unique, realistic customer feedback sentences (10-20 words each).\n",
    "\n",
    "    Customer Profile: {persona}\n",
    "    Sentiment:{sentiment}\n",
    "\n",
    "    - If 'Young Adult': Mention apps, crypto, student loans, splitting bills, fast cash. Use casual language.\n",
    "    - If 'Professional': Mention interest rates, mortgages, wire transfers, business accounts. Use formal language.\n",
    "    - If 'Retiree': Mention branches, pensions, passwords, phone support, safety. Use polite but confused language.\n",
    "\n",
    "    - If Sentiment is 'Positive': Praise speed, features, or service.\n",
    "    - If Sentiment is 'Negative': Complain about fees, crashes, delays, or rejections.\n",
    "\n",
    "    Output format: A raw JSON list of strings. Example: [\"text1\", \"text2\"]\n",
    "    Do not add Markdown formatting or extra text.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=model,\n",
    "            contents=[prompt]\n",
    "        )\n",
    "\n",
    "        # Try multiple ways to get text from the response object\n",
    "        raw_text = None\n",
    "        if hasattr(response, 'text') and isinstance(response.text, str):\n",
    "            raw_text = response.text\n",
    "        else:\n",
    "            # Fallback to stringifying the response\n",
    "            raw_text = str(response)\n",
    "\n",
    "        if raw_text is None:\n",
    "            raise ValueError(\"No text found in model response\")\n",
    "\n",
    "        # Remove common code block markers\n",
    "        cleaned = raw_text.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "\n",
    "        # Search for the first JSON array in the response (robust against extra text)\n",
    "        # Use non-greedy match so we don't accidentally capture across multiple arrays\n",
    "        match = re.search(r\"\\[.*?\\]\", cleaned, re.S)\n",
    "        json_text = match.group(0) if match else cleaned\n",
    "\n",
    "        parsed = json.loads(json_text)\n",
    "\n",
    "        # Normalize to list of non-empty strings\n",
    "        if isinstance(parsed, list):\n",
    "            texts = [str(x).strip() for x in parsed if isinstance(x, str) and str(x).strip()]\n",
    "        else:\n",
    "            # If model returned a dict or other structure, try to find strings inside\n",
    "            texts = []\n",
    "            def _extract_strings(obj):\n",
    "                if isinstance(obj, str):\n",
    "                    return [obj]\n",
    "                if isinstance(obj, dict):\n",
    "                    out = []\n",
    "                    for v in obj.values():\n",
    "                        out.extend(_extract_strings(v))\n",
    "                    return out\n",
    "                if isinstance(obj, list):\n",
    "                    out = []\n",
    "                    for v in obj:\n",
    "                        out.extend(_extract_strings(v))\n",
    "                    return out\n",
    "                return []\n",
    "            texts = [s.strip() for s in _extract_strings(parsed) if s and s.strip()]\n",
    "\n",
    "        # If we still have nothing, raise to hit the exception handler below\n",
    "        if not texts:\n",
    "            raise ValueError(\"Parsed response contained no usable strings\")\n",
    "\n",
    "        # Ensure exactly num_sentences are returned: if fewer, repeat/shuffle to pad\n",
    "        if len(texts) < num_sentences:\n",
    "            # If there are some unique texts, repeat them to reach requested count\n",
    "            orig = texts.copy()\n",
    "            i = 0\n",
    "            while len(texts) < num_sentences and orig:\n",
    "                texts.append(orig[i % len(orig)])\n",
    "                i += 1\n",
    "        elif len(texts) > num_sentences:\n",
    "            texts = texts[:num_sentences]\n",
    "\n",
    "        return texts\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Error fetching/parsing from Gemini: {e}\")\n",
    "        # Return a deterministic fallback list of the requested length\n",
    "        return [\"Error generating text.\" for _ in range(num_sentences)]\n",
    "\n",
    "\n",
    "data_cache = {\n",
    "        \"young_adult\": {\"positive\": [], \"negative\": []},\n",
    "        \"professional\": {\"positive\": [], \"negative\": []},\n",
    "        \"retiree\": {\"positive\": [], \"negative\": []}\n",
    "    }\n",
    "    \n",
    "# --- Young Adult ---\n",
    "ya_positive = generate_customer_feedback(\"Young Adult\", \"Positive\")\n",
    "ya_negative = generate_customer_feedback(\"Young Adult\", \"Negative\")\n",
    "\n",
    "# --- Professional ---\n",
    "pro_positive = generate_customer_feedback(\"Professional\", \"Positive\")\n",
    "pro_negative = generate_customer_feedback(\"Professional\", \"Negative\")\n",
    "\n",
    "# --- Retiree ---\n",
    "ret_positive = generate_customer_feedback(\"Retiree\", \"Positive\")\n",
    "ret_negative = generate_customer_feedback(\"Retiree\", \"Negative\")"
   ],
   "id": "8bb27c01bf73fee4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_feedback_text(persona, is_default):\n",
    "    \"\"\"\n",
    "    Selects a random feedback string based on Persona and Default Status.\n",
    "    \"\"\"\n",
    "    # 1. Determine Base Sentiment\n",
    "    # Default = 1 means they are high risk/struggling -> likely Negative feedback\n",
    "    # Default = 0 means they are repaying -> likely Positive feedback\n",
    "    use_negative_sentiment = (is_default == 1)\n",
    "\n",
    "    # 2. Add \"Noise\"\n",
    "    if random.random() < 0.10:\n",
    "        use_negative_sentiment = not use_negative_sentiment\n",
    "\n",
    "    selected_list = []\n",
    "    \n",
    "    # 3. Select the appropriate list based on Persona and Sentiment\n",
    "    if persona == \"young_adult\":\n",
    "        selected_list = ya_negative if use_negative_sentiment else ya_positive\n",
    "    elif persona == \"professional\":\n",
    "        selected_list = pro_negative if use_negative_sentiment else pro_positive\n",
    "    elif persona == \"retiree\":\n",
    "        selected_list = ret_negative if use_negative_sentiment else ret_positive\n",
    "\n",
    "    # 4. Return a random sentence from selected list\n",
    "    if not selected_list:\n",
    "        return \"Service was okay.\"      \n",
    "    return random.choice(selected_list)"
   ],
   "id": "7bddab386387adba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# SIMULATE DATASET \n",
    "fake = Faker()\n",
    "Faker.seed(42)\n",
    "\n",
    "def generate_data(num_records=1000):\n",
    "    data = []\n",
    "\n",
    "    for _ in range(num_records):\n",
    "        # --- Demographics ---\n",
    "        profile = fake.profile()\n",
    "        customer_id = f\"CUST-{fake.unique.random_int(min=100000, max=999999)}\"\n",
    "        gender = profile['sex']\n",
    "        age = random.randint(18, 80)\n",
    "\n",
    "\n",
    "        # Simulate 3 types customer persona: Young Adult, Professional, Retiree\n",
    "        if age < 25:\n",
    "            persona = \"young_adult\"\n",
    "            job = np.random.choice([\"Student\", \"Intern\", \"Part-time Server\", \"Barista\", \"None\"])\n",
    "            income = np.random.normal(15000, 5000)\n",
    "            spend_score = np.random.normal(70, 10) # High spend relative to income\n",
    "\n",
    "        elif 25 <= age < 60:\n",
    "            persona = \"professional\"\n",
    "            job = profile['job']\n",
    "            income = np.random.normal(85000, 25000)\n",
    "            spend_score = np.random.normal(50, 15)\n",
    "\n",
    "        else:\n",
    "            persona = \"retiree\"\n",
    "            job = \"retired\"\n",
    "            income = np.random.normal(45000, 10000)\n",
    "            spend_score = np.random.normal(30, 10) # Low spend\n",
    "\n",
    "\n",
    "        # --- Transactional Numerics ---\n",
    "        #  Credit score\n",
    "        if persona == \"professional\":\n",
    "            credit_score = int(np.random.normal(720, 50))\n",
    "        elif persona == \"young_adult\":\n",
    "            credit_score = int(np.random.normal(600, 80))\n",
    "        else:\n",
    "            credit_score = int(np.random.normal(680, 60))\n",
    "        \n",
    "        credit_score = max(300, min(850, credit_score)) #real world limits (300-850)\n",
    "\n",
    "        # Account balance\n",
    "        if persona == \"young_adult\":\n",
    "            savings_rate = np.random.normal(0.05, 0.02)\n",
    "            accumulation_factor = random.uniform(0.1, 1.0)\n",
    "\n",
    "        elif persona == \"professional\":\n",
    "            savings_rate = np.random.normal(0.20, 0.05)\n",
    "            accumulation_factor = random.uniform(1.0, 3.0)\n",
    "\n",
    "        else: # Retiree\n",
    "            savings_rate = np.random.normal(0.08, 0.04)\n",
    "            accumulation_factor = random.uniform(2.0, 5.0)\n",
    "\n",
    "        savings_rate = max(0.01, min(0.50, savings_rate))\n",
    "        account_balance = (income * savings_rate) * accumulation_factor * random.uniform(0.1, 1.5)\n",
    "        \n",
    "        # Loan Request Details\n",
    "        max_possible_loan = income * 0.6\n",
    "        loan_amount = round(random.uniform(2000, max_possible_loan), 2)\n",
    "        loan_term = random.choice([12, 24, 36, 60])\n",
    "\n",
    "        risk_probability = 0.1 # Base 10% risk\n",
    "        \n",
    "        # Rule 1: Low Credit Score increases risk significantly\n",
    "        if credit_score < 580: risk_probability += 0.40\n",
    "        elif credit_score < 650: risk_probability += 0.20\n",
    "        \n",
    "        # Rule 2: High Loan-to-Income ratio increases risk\n",
    "        dti_ratio = loan_amount / income\n",
    "        if dti_ratio > 0.4: risk_probability += 0.25\n",
    "        \n",
    "        # Rule 3: Additional risk for Young Adults\n",
    "        if persona == \"young_adult\": risk_probability += 0.05\n",
    "\n",
    "        # Cap probability at 0.95 \n",
    "        risk_probability = min(0.95, risk_probability)\n",
    "\n",
    "        is_default = 1 if random.random() < risk_probability else 0\n",
    "\n",
    "\n",
    "        # --- 4. Feedback Text Column ---\n",
    "        feedback_text = get_feedback_text(persona, is_default)\n",
    "        \n",
    "        record = {\n",
    "            \"Customer_ID\": customer_id,\n",
    "            \"Age\": age,\n",
    "            \"Gender\": gender,\n",
    "            \"Persona\": persona,\n",
    "            \"Job\": job,\n",
    "            \"Annual_Income\": round(income, 2),\n",
    "            \"Credit_Score\": credit_score,\n",
    "            \"Account_Balance\": round(account_balance, 2),\n",
    "            \"Spending_Score\": round(spend_score, 2),\n",
    "            \"Loan_Amount\": loan_amount,\n",
    "            \"Loan_Term_Months\": loan_term,\n",
    "            \"Loan_Default\": is_default, #\n",
    "            \"Customer_Feedback\": feedback_text\n",
    "        }\n",
    "        data.append(record)\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Generate and View\n",
    "df_customers = generate_data(1000)\n",
    "print(df_customers.head())"
   ],
   "id": "d7d835f1efc4539c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save to CSV\n",
    "df_customers.to_csv('financial_data_simulated.csv', index=False)\n",
    "print(f\"Dataset saved to 'financial_data_simulated.csv'\")"
   ],
   "id": "b90553abbac0db7a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Part 2: Feature Engineering and Data Cleaning",
   "id": "7a433ba7b43cdef9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
